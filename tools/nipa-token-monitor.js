#!/usr/bin/env node
/**
 * NIPA GLM API Token Monitor - Standalone Proxy
 *
 * OpenCodeì™€ NIPA API ì‚¬ì´ì—ì„œ ë™ìž‘í•˜ëŠ” íˆ¬ëª… í”„ë¡ì‹œ
 * - ëª¨ë“  API ìš”ì²­/ì‘ë‹µ intercept
 * - usage ì •ë³´ ì‹¤ì‹œê°„ ì¶”ì¶œ ë° ë¡œê¹…
 * - 80% ë„ë‹¬ ì‹œ ê²½ê³ 
 * - OpenCode í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œê³¼ ë…ë¦½ì ìœ¼ë¡œ ë™ìž‘
 */

const http = require('http');
const https = require('https');
const fs = require('fs');
const path = require('path');

// ì¤‘ì•™í™”ëœ ëª¨ë¸ ì„¤ì • ë¡œë“œ
function loadModelConfig() {
  const configPath = path.join(process.env.HOME, '.config', 'opencode', 'nipa-model-config.json');
  try {
    const config = JSON.parse(fs.readFileSync(configPath, 'utf-8'));
    return config.current_model;
  } catch (e) {
    console.warn('Failed to load nipa-model-config.json, using defaults');
    return { context_limit: 262144, model_id: 'Kimi-K2.5' };
  }
}

const MODEL_CONFIG = loadModelConfig();

// ì„¤ì •
const CONFIG = {
  PROXY_PORT: 10347,
  TARGET_HOST: 'proxy2.nipa2025.ktcloud.com',
  TARGET_PORT: 10261,
  CONTEXT_LIMIT: MODEL_CONFIG.context_limit,  // from nipa-model-config.json
  THRESHOLD: 0.8, // 80%
  LOG_DIR: path.join(process.env.HOME, '.config', 'opencode', 'logs'),
  LOG_FILE: 'nipa-token-monitor.log',
  USAGE_FILE: 'nipa-usage.json',  // í”ŒëŸ¬ê·¸ì¸ ë¸Œë¦¿ì§€ìš© usage íŒŒì¼
  RESPONSE_LOG: 'nipa-responses.jsonl'  // assistant ì‘ë‹µ ë¡œê·¸
};

// ì„¸ì…˜ë³„ í† í° ì¶”ì 
const sessionTokens = new Map();

// ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
if (!fs.existsSync(CONFIG.LOG_DIR)) {
  fs.mkdirSync(CONFIG.LOG_DIR, { recursive: true });
}

const logFilePath = path.join(CONFIG.LOG_DIR, CONFIG.LOG_FILE);

function log(level, message, data = null) {
  const timestamp = new Date().toISOString();
  const logEntry = {
    timestamp,
    level,
    message,
    ...(data && { data })
  };

  const logLine = `[${timestamp}] [${level}] ${message}${data ? ' ' + JSON.stringify(data) : ''}\n`;

  // íŒŒì¼ ë¡œê·¸
  fs.appendFileSync(logFilePath, logLine, 'utf-8');

  // ì½˜ì†” ì¶œë ¥ (ì¤‘ìš”í•œ ê²ƒë§Œ)
  if (level === 'WARN' || level === 'ERROR' || level === 'ALERT') {
    console.log(logLine.trim());
  }
}

function extractUsageFromResponse(responseBody) {
  try {
    const data = JSON.parse(responseBody);
    return data.usage || null;
  } catch (error) {
    return null;
  }
}

// ëˆ„ì  ìš”ì²­ ìˆ˜
let requestCount = 0;

function writeUsageFile(usage) {
  try {
    const usageFilePath = path.join(CONFIG.LOG_DIR, CONFIG.USAGE_FILE);
    const data = {
      timestamp: new Date().toISOString(),
      prompt_tokens: usage.prompt_tokens || 0,
      completion_tokens: usage.completion_tokens || 0,
      total_tokens: usage.total_tokens || 0,
      context_limit: CONFIG.CONTEXT_LIMIT,
      usage_percentage: (usage.prompt_tokens || 0) / CONFIG.CONTEXT_LIMIT,
      request_count: requestCount
    };
    fs.writeFileSync(usageFilePath, JSON.stringify(data, null, 2), 'utf-8');
    log('INFO', 'Usage file written', { path: usageFilePath, prompt_tokens: data.prompt_tokens });
  } catch (e) {
    log('ERROR', 'Failed to write usage file', { error: e.message });
  }
}

function trackTokenUsage(sessionId, usage) {
  if (!usage) return;

  const promptTokens = usage.prompt_tokens || 0;
  const usagePercentage = promptTokens / CONFIG.CONTEXT_LIMIT;

  sessionTokens.set(sessionId, {
    promptTokens,
    completionTokens: usage.completion_tokens || 0,
    totalTokens: usage.total_tokens || 0,
    usagePercentage,
    timestamp: Date.now()
  });

  log('INFO', 'Token usage tracked', {
    sessionId,
    promptTokens,
    percentage: `${(usagePercentage * 100).toFixed(1)}%`,
    threshold: `${(CONFIG.THRESHOLD * 100).toFixed(0)}%`
  });

  // íŒŒì¼ ë¸Œë¦¿ì§€: usage JSON ê¸°ë¡
  writeUsageFile(usage);

  // ìž„ê³„ê°’ ì²´í¬
  if (usagePercentage >= CONFIG.THRESHOLD) {
    log('ALERT', 'THRESHOLD REACHED! Compaction recommended!', {
      sessionId,
      promptTokens,
      percentage: `${(usagePercentage * 100).toFixed(1)}%`
    });
  } else if (usagePercentage >= CONFIG.THRESHOLD * 0.9) {
    log('WARN', 'Approaching threshold (90%)', {
      sessionId,
      promptTokens,
      percentage: `${(usagePercentage * 100).toFixed(1)}%`
    });
  }
}

// SSE ì²­í¬ì—ì„œ assistant content ì¶”ì¶œ
function extractContentFromSSE(sseBuffer) {
  const lines = sseBuffer.split('\n');
  let content = '';
  let reasoningContent = '';

  for (const line of lines) {
    if (line.startsWith('data: ') && !line.includes('[DONE]')) {
      try {
        const data = JSON.parse(line.slice(6));
        const delta = data.choices?.[0]?.delta;
        if (delta?.content) content += delta.content;
        if (delta?.reasoning_content) reasoningContent += delta.reasoning_content;
      } catch (e) {}
    }
  }
  return { content, reasoning: reasoningContent };
}

// assistant ì‘ë‹µì„ JSONL íŒŒì¼ì— ê¸°ë¡
function logResponse(extracted, usage) {
  try {
    const responseLogPath = path.join(CONFIG.LOG_DIR, CONFIG.RESPONSE_LOG);
    const entry = {
      timestamp: new Date().toISOString(),
      reasoning: extracted.reasoning || undefined,
      content: extracted.content || undefined,
      tokens: usage ? { prompt: usage.prompt_tokens, completion: usage.completion_tokens } : null,
      request_num: requestCount
    };
    fs.appendFileSync(responseLogPath, JSON.stringify(entry) + '\n', 'utf-8');
  } catch (e) {
    log('ERROR', 'Failed to write response log', { error: e.message });
  }
}

// SSE ì²­í¬ì—ì„œ usage ì¶”ì¶œ
function extractUsageFromSSE(sseBuffer) {
  const lines = sseBuffer.split('\n');
  let lastUsage = null;

  for (const line of lines) {
    if (line.startsWith('data: ') && !line.includes('[DONE]')) {
      try {
        const data = JSON.parse(line.slice(6));
        if (data.usage) {
          lastUsage = data.usage;
        }
      } catch (e) {
        // íŒŒì‹± ë¶ˆê°€í•œ ì²­í¬ ë¬´ì‹œ
      }
    }
  }
  return lastUsage;
}

// Proxy ì„œë²„ ìƒì„±
const proxyServer = http.createServer((req, res) => {
  let requestBody = '';

  req.on('data', chunk => {
    requestBody += chunk.toString();
  });

  req.on('end', () => {
    let modifiedBody = requestBody;
    let modifiedHeaders = { ...req.headers };
    let isStreamingRequest = false;

    // ìŠ¤íŠ¸ë¦¬ë° ìœ ì§€ + stream_options.include_usage ì¶”ê°€
    if (requestBody && req.url.includes('/chat/completions')) {
      try {
        const bodyData = JSON.parse(requestBody);
        isStreamingRequest = bodyData.stream === true;

        if (isStreamingRequest) {
          // usageë¥¼ ìŠ¤íŠ¸ë¦¬ë° ë§ˆì§€ë§‰ ì²­í¬ì— í¬í•¨ì‹œí‚¤ë„ë¡ ìš”ì²­
          bodyData.stream_options = { include_usage: true };
          modifiedBody = JSON.stringify(bodyData);
          modifiedHeaders['content-length'] = Buffer.byteLength(modifiedBody);
        }

        log('DEBUG', 'Request intercepted', {
          streaming: isStreamingRequest,
          hasStreamOptions: !!bodyData.stream_options
        });
      } catch (e) {
        log('WARN', 'Failed to parse request body', { error: e.message });
      }
    }

    requestCount++;

    // NIPA ì¿ í‚¤ ì£¼ìž… (í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ìŒ)
    const nipaCookie = process.env.NIPA_COOKIE || '';
    if (nipaCookie) {
      modifiedHeaders['cookie'] = nipaCookie;
    }

    const options = {
      hostname: CONFIG.TARGET_HOST,
      port: CONFIG.TARGET_PORT,
      path: req.url,
      method: req.method,
      headers: {
        ...modifiedHeaders,
        host: CONFIG.TARGET_HOST
      },
      rejectUnauthorized: false  // NIPA ì¸ì¦ì„œ ê²€ì¦ ìŠ¤í‚µ
    };

    const proxyReq = https.request(options, (proxyRes) => {
      const contentType = proxyRes.headers['content-type'] || '';
      const isSSE = contentType.includes('text/event-stream');

      if (isSSE) {
        // === SSE íˆ¬ëª… ì „ë‹¬ + usage ì¶”ì¶œ ===
        res.writeHead(proxyRes.statusCode, proxyRes.headers);
        let sseBuffer = '';

        proxyRes.on('data', (chunk) => {
          // í´ë¼ì´ì–¸íŠ¸ì— ì¦‰ì‹œ ì „ë‹¬ (ì§€ì—° ì—†ìŒ)
          res.write(chunk);
          sseBuffer += chunk.toString();
        });

        proxyRes.on('end', () => {
          res.end();

          // ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ í›„ usage ì¶”ì¶œ + ì‘ë‹µ ë¡œê¹…
          const usage = extractUsageFromSSE(sseBuffer);
          const extracted = extractContentFromSSE(sseBuffer);
          if (extracted.content || extracted.reasoning) {
            logResponse(extracted, usage);
          }
          if (usage) {
            let sessionId = 'default';
            try {
              const reqData = JSON.parse(requestBody);
              sessionId = reqData.session_id || reqData.sessionId || 'default';
            } catch (e) {}
            trackTokenUsage(sessionId, usage);
            log('INFO', 'SSE usage extracted', { prompt_tokens: usage.prompt_tokens });
          } else {
            log('WARN', 'No usage in SSE stream (NIPA may not support stream_options.include_usage)');
          }
        });
      } else {
        // === ë¹„ìŠ¤íŠ¸ë¦¬ë°: ì „ì²´ ì‘ë‹µ ìˆ˜ì§‘ ===
        let responseBody = '';
        proxyRes.on('data', chunk => { responseBody += chunk.toString(); });

        proxyRes.on('end', () => {
          const usage = extractUsageFromResponse(responseBody);
          // ë¹„SSE ì‘ë‹µ ë¡œê¹…
          try {
            const resData = JSON.parse(responseBody);
            const msg = resData.choices?.[0]?.message;
            const extracted = { content: msg?.content || '', reasoning: msg?.reasoning_content || '' };
            if (extracted.content || extracted.reasoning) logResponse(extracted, usage);
          } catch (e) {}
          if (usage) {
            let sessionId = 'default';
            try {
              const reqData = JSON.parse(requestBody);
              sessionId = reqData.session_id || reqData.sessionId || 'default';
            } catch (e) {}
            trackTokenUsage(sessionId, usage);
          }

          res.writeHead(proxyRes.statusCode, proxyRes.headers);
          res.end(responseBody);
        });
      }
    });

    proxyReq.on('error', (error) => {
      log('ERROR', 'Proxy request failed', { error: error.message });
      res.writeHead(502, { 'Content-Type': 'text/plain' });
      res.end('Bad Gateway: ' + error.message);
    });

    if (modifiedBody) {
      proxyReq.write(modifiedBody);
    }
    proxyReq.end();
  });
});

// ì„œë²„ ì‹œìž‘
proxyServer.listen(CONFIG.PROXY_PORT, () => {
  console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  NIPA Token Monitor Proxy                                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Proxy server running on: http://localhost:${CONFIG.PROXY_PORT}
ðŸŽ¯ Target API: https://${CONFIG.TARGET_HOST}:${CONFIG.TARGET_PORT}
ðŸ“Š Context limit: ${CONFIG.CONTEXT_LIMIT} tokens
âš ï¸  Threshold: ${(CONFIG.THRESHOLD * 100).toFixed(0)}%
ðŸ“ Log file: ${logFilePath}

ðŸ“Œ OpenCode Configuration:
   Update opencode.json:
   {
     "provider": {
       "nipa-glm-tool-calling": {
         "options": {
           "baseURL": "http://localhost:${CONFIG.PROXY_PORT}/v1"
         }
       }
     }
   }

Press Ctrl+C to stop
  `);

  log('INFO', 'Proxy server started', {
    port: CONFIG.PROXY_PORT,
    target: `${CONFIG.TARGET_HOST}:${CONFIG.TARGET_PORT}`
  });
});

// ì¢…ë£Œ ì²˜ë¦¬
process.on('SIGINT', () => {
  console.log('\n\nðŸ›‘ Shutting down proxy server...');
  log('INFO', 'Proxy server stopped');

  // ìµœì¢… í†µê³„ ì¶œë ¥
  console.log('\nðŸ“Š Session Statistics:');
  for (const [sessionId, data] of sessionTokens.entries()) {
    console.log(`  ${sessionId}: ${data.totalTokens} tokens (${(data.usagePercentage * 100).toFixed(1)}%)`);
  }

  process.exit(0);
});

// ì—ëŸ¬ ì²˜ë¦¬
process.on('uncaughtException', (error) => {
  log('ERROR', 'Uncaught exception', { error: error.message, stack: error.stack });
  console.error('Fatal error:', error);
  process.exit(1);
});
