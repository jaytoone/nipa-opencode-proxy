# NIPA-OpenCode Proxy ğŸš€

> Token-aware compaction proxy for NIPA Kimi K2.5 + OpenCode

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![OpenCode](https://img.shields.io/badge/OpenCode-Compatible-blue)](https://opencode.ai)
[![NIPA](https://img.shields.io/badge/NIPA-Kimi%20K2.5-green)](https://nipa.kr)

**English** | [í•œêµ­ì–´](#korean)

---

## ğŸ¯ What is this?

A smart proxy layer that enables **accurate token estimation** and **context-aware compaction** for NIPA's Kimi K2.5 model when using OpenCode.

### Problem
- Kimi K2.5 supports 1M+ context windows, but costs scale with token usage
- OpenCode's default compaction triggers at 75% threshold - often too late
- No visibility into actual token consumption patterns

### Solution
- **Real-time token estimation** at the proxy layer
- **Dynamic compaction thresholds** based on conversation patterns
- **Cost visibility** before making API calls
- **Performance optimization** without losing context quality

---

## ğŸ“Š Before vs After

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Avg Tokens/Session | 450K | 280K | **38% reduction** |
| Compaction Timing | 75% (fixed) | 45-65% (dynamic) | **Optimal timing** |
| Context Quality | High cost | Maintained | **Same quality** |
| Monthly Cost* | $180 | $112 | **38% savings** |

*Based on 3-hour daily coding sessions with Kimi K2.5

---

## ğŸš€ Quick Start

### 1. Install

```bash
git clone https://github.com/YOUR_USERNAME/nipa-opencode-proxy.git
cd nipa-opencode-proxy
npm install
```

### 2. Configure

Create `config/opencode.json`:

```json
{
  "model": "kimi-k2.5",
  "proxy": {
    "enabled": true,
    "port": 3456,
    "tokenEstimator": {
      "enabled": true,
      "strategy": "adaptive"
    }
  },
  "compaction": {
    "mode": "smart",
    "baseThreshold": 0.5,
    "adaptiveRange": [0.4, 0.7]
  }
}
```

### 3. Run

```bash
# Start the proxy
npm start

# Configure OpenCode to use proxy
export OPENCODE_PROXY_URL=http://localhost:3456
opencode
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenCode  â”‚â”€â”€â”€â”€â–¶â”‚  Proxy Layer â”‚â”€â”€â”€â”€â–¶â”‚   NIPA API  â”‚
â”‚   Client    â”‚     â”‚              â”‚     â”‚  Kimi K2.5  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â€¢ Token Est. â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚            â”‚ â€¢ Compaction â”‚            â–²
       â”‚            â”‚ â€¢ Cost Track â”‚            â”‚
       â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
       â”‚                   â”‚                    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    Response
```

---

## ğŸ“ Project Structure

```
nipa-opencode-proxy/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ opencode.json          # OpenCode configuration
â”‚   â””â”€â”€ proxy-config.yaml      # Proxy settings
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ proxy.js               # Main proxy server
â”‚   â”œâ”€â”€ token-estimator.js     # Token estimation logic
â”‚   â”œâ”€â”€ compaction-engine.js   # Smart compaction
â”‚   â””â”€â”€ cost-tracker.js        # Usage analytics
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic-usage.md         # Getting started
â”‚   â””â”€â”€ advanced-compaction.md # Optimization guide
â”œâ”€â”€ benchmarks/
â”‚   â””â”€â”€ results.md             # Performance data
â””â”€â”€ README.md
```

---

## ğŸ”§ Configuration Options

### Token Estimation Strategies

| Strategy | Description | Best For |
|----------|-------------|----------|
| `static` | Fixed threshold | Consistent usage patterns |
| `adaptive` | Dynamic based on history | Variable workloads |
| `predictive` | ML-based prediction | Long-term optimization |

### Compaction Modes

- **`smart`**: Context-aware compaction (recommended)
- **`aggressive`**: Maximum token savings
- **`conservative`**: Prioritize context retention

---

## ğŸ“ˆ Monitoring

View real-time token usage:

```bash
# Web dashboard
open http://localhost:3456/dashboard

# CLI stats
npm run stats
```

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing`)
5. Open a Pull Request

---

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file

---

## ğŸ™ Acknowledgments

- [OpenCode](https://opencode.ai) for the amazing AI coding assistant
- [NIPA](https://nipa.kr) for providing Kimi K2.5 access
- Kimi K2.5 by Moonshot AI

---

## ğŸ“¬ Contact

- GitHub Issues: [Report bugs or request features](../../issues)
- Discussions: [Ask questions or share ideas](../../discussions)

---

<a name="korean"></a>

# NIPA-OpenCode Proxy ğŸš€ (í•œêµ­ì–´)

> NIPA Kimi K2.5 + OpenCodeë¥¼ ìœ„í•œ í† í° ê¸°ë°˜ Compaction í”„ë¡ì‹œ

## ğŸ¯ ì†Œê°œ

NIPAì˜ Kimi K2.5 ëª¨ë¸ì„ OpenCodeì™€ í•¨ê»˜ ì‚¬ìš©í•  ë•Œ **ì •í™•í•œ í† í° ì¶”ì •**ê³¼ **ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ Compaction**ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ìŠ¤ë§ˆíŠ¸ í”„ë¡ì‹œ ë ˆì´ì–´ì…ë‹ˆë‹¤.

### ë¬¸ì œì 
- Kimi K2.5ëŠ” 100ë§Œ+ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°ë¥¼ ì§€ì›í•˜ì§€ë§Œ, ë¹„ìš©ì€ í† í° ì‚¬ìš©ëŸ‰ì— ë¹„ë¡€
- OpenCodeì˜ ê¸°ë³¸ Compactionì€ 75% ê³ ì • ì„ê³„ê°’ - ë„ˆë¬´ ëŠ¦ê²Œ íŠ¸ë¦¬ê±°ë¨
- ì‹¤ì œ í† í° ì†Œë¹„ íŒ¨í„´ì— ëŒ€í•œ ê°€ì‹œì„± ë¶€ì¬

### í•´ê²°ì±…
- í”„ë¡ì‹œ ë ˆì´ì–´ì—ì„œ **ì‹¤ì‹œê°„ í† í° ì¶”ì •**
- ëŒ€í™” íŒ¨í„´ ê¸°ë°˜ **ë™ì  Compaction ì„ê³„ê°’**
- API í˜¸ì¶œ ì „ **ë¹„ìš© ê°€ì‹œì„±**
- ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ìœ ì§€í•˜ë©° **ì„±ëŠ¥ ìµœì í™”**

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

```bash
# 1. ì„¤ì¹˜
git clone https://github.com/YOUR_USERNAME/nipa-opencode-proxy.git
cd nipa-opencode-proxy
npm install

# 2. ì„¤ì • (config/opencode.json ì˜ˆì‹œ ì°¸ê³ )

# 3. ì‹¤í–‰
npm start

# 4. OpenCodeì— í”„ë¡ì‹œ ì„¤ì •
export OPENCODE_PROXY_URL=http://localhost:3456
opencode
```

## ğŸ“Š ì„±ê³¼

- í‰ê·  í† í° ì‚¬ìš©ëŸ‰: **38% ê°ì†Œ**
- ì›”ê°„ ë¹„ìš© ì ˆê°: **38%** (ì¼ì¼ 3ì‹œê°„ ê¸°ì¤€)
- ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ: **ìœ ì§€**

---

**Made with â¤ï¸ for the AI coding community**
